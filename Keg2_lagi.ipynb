{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Keg2 lagi.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/annisapraditha/tugaspraktikum_ML4/blob/main/Keg2_lagi.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r2L6_bzZdjXm"
      },
      "source": [
        "!pip install -q kaggle==1.5.8"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "akyNHL9GdjTv",
        "outputId": "51b3df34-df93-42f4-ddc8-83cf8e828637"
      },
      "source": [
        "!pip install opendatasets"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting opendatasets\n",
            "  Downloading opendatasets-0.1.20-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: tqdm in c:\\users\\annisa praditha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from opendatasets) (4.62.3)\n",
            "Collecting click\n",
            "  Downloading click-8.0.3-py3-none-any.whl (97 kB)\n",
            "Requirement already satisfied: kaggle in c:\\users\\annisa praditha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from opendatasets) (1.5.8)\n",
            "Requirement already satisfied: colorama in c:\\users\\annisa praditha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from click->opendatasets) (0.4.4)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in c:\\users\\annisa praditha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from kaggle->opendatasets) (1.24.3)\n",
            "Requirement already satisfied: six>=1.10 in c:\\users\\annisa praditha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from kaggle->opendatasets) (1.16.0)\n",
            "Requirement already satisfied: certifi in c:\\users\\annisa praditha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from kaggle->opendatasets) (2021.10.8)\n",
            "Requirement already satisfied: python-dateutil in c:\\users\\annisa praditha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from kaggle->opendatasets) (2.8.2)\n",
            "Requirement already satisfied: requests in c:\\users\\annisa praditha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from kaggle->opendatasets) (2.26.0)\n",
            "Requirement already satisfied: python-slugify in c:\\users\\annisa praditha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from kaggle->opendatasets) (5.0.2)\n",
            "Requirement already satisfied: slugify in c:\\users\\annisa praditha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from kaggle->opendatasets) (0.0.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in c:\\users\\annisa praditha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from python-slugify->kaggle->opendatasets) (1.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\annisa praditha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->kaggle->opendatasets) (3.3)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\annisa praditha\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->kaggle->opendatasets) (2.0.8)\n",
            "Installing collected packages: click, opendatasets\n",
            "Successfully installed click-8.0.3 opendatasets-0.1.20\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tz_FiL60edR1"
      },
      "source": [
        "!pip install tensorflow"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m4ZfyHg4zTLB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3cda22f5-60c8-4595-d901-bd022355e981"
      },
      "source": [
        "from google.colab import drive \n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fQhKpfePqa3U"
      },
      "source": [
        "import os\n",
        "os.environ['KAGGLE_CONFIG_DIR'] = \"/content/drive/MyDrive/modul 4\""
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kfzNGGb30o08",
        "outputId": "2710bfa8-195c-47f5-b19c-2f58d267990b"
      },
      "source": [
        "cd /content/drive/MyDrive/modul 4/"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/modul 4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1nk4skI10sAC",
        "outputId": "06911e49-b1c9-464a-dd85-e5de61562ecd"
      },
      "source": [
        "ls "
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[0m\u001b[01;34mcoba\u001b[0m/        \u001b[01;34moutput\u001b[0m/                                             \u001b[01;34mskin-lesions\u001b[0m/\n",
            "kaggle.json  skin-lesion-analysis-toward-melanoma-detection.zip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "foKlUTOKzdib"
      },
      "source": [
        "!kaggle datasets download -d wanderdust/skin-lesion-analysis-toward-melanoma-detection"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TdFfb2B7seYb"
      },
      "source": [
        "!unzip \\*.zip && rm *.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VkN8Sd0pzdvY"
      },
      "source": [
        "train_dir = \"train\" \n",
        "test_dir = \"test\"\n",
        "valid_dir = \"val\""
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L3ZwfVw0zdzI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f1d01553-289c-40d1-8da3-be0c397aceec"
      },
      "source": [
        "!pip install split-folders"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting split-folders\n",
            "  Downloading split_folders-0.4.3-py3-none-any.whl (7.4 kB)\n",
            "Installing collected packages: split-folders\n",
            "Successfully installed split-folders-0.4.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "caBtb70lzd2M"
      },
      "source": [
        "import splitfolders  \n",
        "\n",
        "splitfolders.ratio(\"coba\", output=\"output\", seed=1337, ratio=(.80, .19, .01), group_prefix=None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "8gd3L5bhq-2s",
        "outputId": "cad7e54c-b27c-4682-f4b8-916883b58369"
      },
      "source": [
        "pwd"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/drive/My Drive/modul 4'"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XVLOtGIArDSj",
        "outputId": "814952fb-99f3-40b0-ae8b-753d9d58e24d"
      },
      "source": [
        "ls"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[0m\u001b[01;34mcoba\u001b[0m/        \u001b[01;34moutput\u001b[0m/                                             \u001b[01;34mskin-lesions\u001b[0m/\n",
            "kaggle.json  skin-lesion-analysis-toward-melanoma-detection.zip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MPsHggYZzd7P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "451dfb19-c01b-4cf7-c6e6-ce0f9c6999ff"
      },
      "source": [
        "ls output"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[0m\u001b[01;34mtest\u001b[0m/  \u001b[01;34mtrain\u001b[0m/  \u001b[01;34mval\u001b[0m/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oYsye5H_zd-S"
      },
      "source": [
        "train_path = \"output/train\" \n",
        "test_path  = \"output/test\"\n",
        "val_path   = \"output/val\""
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EzHkhPDdzeD_"
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator #run\n",
        "\n",
        "train_datagen = ImageDataGenerator(rescale=1./255,\n",
        "                                   shear_range=0.2,\n",
        "                                   zoom_range=0.2,\n",
        "                                   horizontal_flip=True)\n",
        "val_datagen = ImageDataGenerator(rescale=1./255)"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "47BRlg-IzeG3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f2172c6e-cd30-4185-a9d0-43ed928cd5f6"
      },
      "source": [
        "training_set = train_datagen.flow_from_directory(  train_path, \n",
        "                                       target_size=(128, 128),\n",
        "                                             color_mode=\"rgb\",\n",
        "                                                batch_size=32,\n",
        "                                     class_mode='categorical',\n",
        "                                               shuffle = True)"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2198 images belonging to 3 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "APNLZYTP0OxJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aab47609-e429-4090-f92b-8f4cebd760d9"
      },
      "source": [
        "validation_set = val_datagen.flow_from_directory(    val_path, \n",
        "                                       target_size=(128, 128),\n",
        "                                             color_mode=\"rgb\",\n",
        "                                                batch_size=32,\n",
        "                                     class_mode='categorical',\n",
        "                                               shuffle = False)"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 521 images belonging to 3 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mElCJssQ0Ozv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a989cef3-06db-4470-a28d-e46445840cba"
      },
      "source": [
        "test_set = val_datagen.flow_from_directory(         test_path, \n",
        "                                       target_size=(128, 128),\n",
        "                                             color_mode=\"rgb\",\n",
        "                                                batch_size=32,\n",
        "                                     class_mode='categorical',\n",
        "                                               shuffle = False)"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 31 images belonging to 3 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QjPFpNp_0O4i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d7001307-a573-42c2-ee92-058f48464abe"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Conv2D, Activation, Flatten, MaxPool2D, BatchNormalization\n",
        "from tensorflow.keras.optimizers import Adam, RMSprop\n",
        "\n",
        "model1 = Sequential([\n",
        "                     Conv2D(32, kernel_size=3, activation='relu', input_shape=(128, 128, 3)),\n",
        "                     MaxPool2D(2,2),\n",
        "\n",
        "                     Conv2D(64, kernel_size=3, activation='relu'),\n",
        "                     MaxPool2D(2,2),\n",
        "                     BatchNormalization(),\n",
        "\n",
        "                     Conv2D(128, kernel_size=3, activation='relu'),\n",
        "                     MaxPool2D(2,2),\n",
        "\n",
        "                     Conv2D(256, kernel_size=3, activation='relu'),\n",
        "                     MaxPool2D(2,2),\n",
        "\n",
        "                     Dropout(0.25),\n",
        "\n",
        "                     Flatten(),\n",
        "\n",
        "                     Dense(128, activation='relu'),\n",
        "                     Dense(3, activation='softmax')\n",
        "])\n",
        "\n",
        "model1.summary()"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_16 (Conv2D)          (None, 126, 126, 32)      896       \n",
            "                                                                 \n",
            " max_pooling2d_16 (MaxPoolin  (None, 63, 63, 32)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_17 (Conv2D)          (None, 61, 61, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_17 (MaxPoolin  (None, 30, 30, 64)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " batch_normalization_4 (Batc  (None, 30, 30, 64)       256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " conv2d_18 (Conv2D)          (None, 28, 28, 128)       73856     \n",
            "                                                                 \n",
            " max_pooling2d_18 (MaxPoolin  (None, 14, 14, 128)      0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_19 (Conv2D)          (None, 12, 12, 256)       295168    \n",
            "                                                                 \n",
            " max_pooling2d_19 (MaxPoolin  (None, 6, 6, 256)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 6, 6, 256)         0         \n",
            "                                                                 \n",
            " flatten_4 (Flatten)         (None, 9216)              0         \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 128)               1179776   \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 3)                 387       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,568,835\n",
            "Trainable params: 1,568,707\n",
            "Non-trainable params: 128\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aML1-8QX0O7A"
      },
      "source": [
        "model1.compile(loss='categorical_crossentropy',\n",
        "              optimizer=Adam(learning_rate=0.0001),\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NfICi1sf0O9x",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "42c759a2-db95-4fce-f843-d6cb5e318724"
      },
      "source": [
        "import time\n",
        "\n",
        "start=time.time()\n",
        "history = model1.fit(training_set,\n",
        "          epochs=100,\n",
        "          steps_per_epoch=10,\n",
        "          validation_data=validation_set\n",
        "          )"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "10/10 [==============================] - 226s 24s/step - loss: 0.9035 - accuracy: 0.6219 - val_loss: 1.0098 - val_accuracy: 0.6718\n",
            "Epoch 2/100\n",
            "10/10 [==============================] - 200s 22s/step - loss: 0.8530 - accuracy: 0.6581 - val_loss: 1.0223 - val_accuracy: 0.6718\n",
            "Epoch 3/100\n",
            "10/10 [==============================] - 219s 23s/step - loss: 0.7669 - accuracy: 0.7097 - val_loss: 1.0096 - val_accuracy: 0.6718\n",
            "Epoch 4/100\n",
            " 8/10 [=======================>......] - ETA: 16s - loss: 0.8201 - accuracy: 0.6680"
          ]
        },
        {
          "output_type": "error",
          "ename": "UnknownError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mUnknownError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-63-0e8f8de96ede>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m           \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m           \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m           \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m           )\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 59\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     60\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mUnknownError\u001b[0m:  OSError: image file is truncated (51 bytes not processed)\nTraceback (most recent call last):\n\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/script_ops.py\", line 275, in __call__\n    ret = func(*args)\n\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py\", line 649, in wrapper\n    return func(*args, **kwargs)\n\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/dataset_ops.py\", line 992, in generator_py_func\n    values = next(generator_state.get_iterator(iterator_id))\n\n  File \"/usr/local/lib/python3.7/dist-packages/keras/engine/data_adapter.py\", line 834, in wrapped_generator\n    for data in generator_fn():\n\n  File \"/usr/local/lib/python3.7/dist-packages/keras/engine/data_adapter.py\", line 960, in generator_fn\n    yield x[i]\n\n  File \"/usr/local/lib/python3.7/dist-packages/keras_preprocessing/image/iterator.py\", line 65, in __getitem__\n    return self._get_batches_of_transformed_samples(index_array)\n\n  File \"/usr/local/lib/python3.7/dist-packages/keras_preprocessing/image/iterator.py\", line 230, in _get_batches_of_transformed_samples\n    interpolation=self.interpolation)\n\n  File \"/usr/local/lib/python3.7/dist-packages/keras_preprocessing/image/utils.py\", line 138, in load_img\n    img = img.resize(width_height_tuple, resample)\n\n  File \"/usr/local/lib/python3.7/dist-packages/PIL/Image.py\", line 1886, in resize\n    self.load()\n\n  File \"/usr/local/lib/python3.7/dist-packages/PIL/ImageFile.py\", line 247, in load\n    \"(%d bytes not processed)\" % len(b)\n\nOSError: image file is truncated (51 bytes not processed)\n\n\n\t [[{{node PyFunc}}]]\n\t [[IteratorGetNext]] [Op:__inference_train_function_10515]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Q2usKk20wiS"
      },
      "source": [
        "\n",
        "print(\"waktu = \", time.time() - start, \"detik\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "akvKE7IF0O_T"
      },
      "source": [
        "score = model1.evaluate(train_generator)\n",
        "\n",
        "print('Loss: {:.2f}'.format(score[0]))\n",
        "print('Accuracy: {:.2f}'.format(score[1]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l6l5mlIL0fli"
      },
      "source": [
        "score = model1.evaluate(val_generator)\n",
        "\n",
        "print('Loss: {:.2f}'.format(score[0]))\n",
        "print('Accuracy: {:.2f}'.format(score[1]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VmAwIxFD0fn5"
      },
      "source": [
        "score = model1.evaluate(test_generator)\n",
        "\n",
        "print('Loss: {:.2f}'.format(score[0]))\n",
        "print('Accuracy: {:.2f}'.format(score[1]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4eIRFeOc0fp7"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "plt.style.use(\"ggplot\")\n",
        "plt.figure(figsize=(12,7))\n",
        "plt.plot(history.history[\"loss\"], label=\"train_loss\")\n",
        "plt.plot(history.history[\"val_loss\"], label=\"val_loss\")\n",
        "plt.title(\"Loss Plot\")\n",
        "plt.xlabel(\"Epoch #\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "plt.style.use(\"ggplot\")\n",
        "plt.figure(figsize=(12,7))\n",
        "plt.plot(history.history[\"accuracy\"], label=\"train_acc\")\n",
        "plt.plot(history.history[\"val_accuracy\"], label=\"val_acc\")\n",
        "plt.title(\"Accuracy Plot\")\n",
        "plt.xlabel(\"Epoch #\")\n",
        "plt.ylabel(\"Acc\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tyM_Chev0fsa"
      },
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc\n",
        "import numpy as np\n",
        "\n",
        "pred = model1.predict(test_generator)\n",
        "labels = (pred > 0.5).astype(np.int)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZYtx4K3d0fu1"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "model_ann = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.InputLayer(input_shape=(250,250,3)),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(32, activation='relu'),\n",
        "    tf.keras.layers.Dense(64, activation='relu'),\n",
        "    tf.keras.layers.Dense(128, activation='relu'),\n",
        "    tf.keras.layers.Dense(5, activation='softmax'),\n",
        "])\n",
        "\n",
        "model_ann.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u91j6OnG0fwm"
      },
      "source": [
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# Compile model\n",
        "model_ann.compile(loss='categorical_crossentropy',\n",
        "              optimizer=Adam(learning_rate=0.0001),\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EJIYfRJd0fyz"
      },
      "source": [
        "start=time.time()\n",
        "history2 = model_ann.fit(train_generator,\n",
        "          epochs=100,\n",
        "          validation_data=val_generator,\n",
        "          verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DJUA3hza0f02"
      },
      "source": [
        "print(\"waktu = \", time.time() - start, \"detik\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IQlpAEdg0PEX"
      },
      "source": [
        "score = model_ann.evaluate(train_generator)\n",
        "\n",
        "print('Loss: {:.2f}'.format(score[0]))\n",
        "print('Accuracy: {:.2f}'.format(score[1]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "olEvJwdc05iw"
      },
      "source": [
        "score = model_ann.evaluate(val_generator)\n",
        "\n",
        "print('Loss: {:.2f}'.format(score[0]))\n",
        "print('Accuracy: {:.2f}'.format(score[1]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SqySucuG05lS"
      },
      "source": [
        "score = model_ann.evaluate(test_generator)\n",
        "\n",
        "print('Loss: {:.2f}'.format(score[0]))\n",
        "print('Accuracy: {:.2f}'.format(score[1]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aSRChm4j05np"
      },
      "source": [
        "plt.style.use(\"ggplot\")\n",
        "plt.figure(figsize=(12,7))\n",
        "plt.plot(history2.history[\"loss\"], label=\"train_loss\")\n",
        "plt.plot(history2.history[\"val_loss\"], label=\"val_loss\")\n",
        "plt.title(\"Loss Plot\")\n",
        "plt.xlabel(\"Epoch #\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "plt.style.use(\"ggplot\")\n",
        "plt.figure(figsize=(12,7))\n",
        "plt.plot(history2.history[\"accuracy\"], label=\"train_acc\")\n",
        "plt.plot(history2.history[\"val_accuracy\"], label=\"val_acc\")\n",
        "plt.title(\"Accuracy Plot\")\n",
        "plt.xlabel(\"Epoch #\")\n",
        "plt.ylabel(\"Acc\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VzoulR8s05so"
      },
      "source": [
        "pred2 = model_ann.predict(test_generator)\n",
        "labels = (pred2 > 0.5).astype(np.int)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kp-LSdci05vA"
      },
      "source": [
        "# model1.save(\"model1_diabet.h5\")\n",
        "# model2.save(\"model2_diabet.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kDBKnkwX05xk"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorboard.plugins.hparams import api as hp"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BMMyfNKa05z5"
      },
      "source": [
        "%load_ext tensorboard"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kk-AkWX11GnB"
      },
      "source": [
        "!rm -rf ./logs/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "018fP6sR1Gsl"
      },
      "source": [
        "HP_NUM_UNITS = hp.HParam('num_units', hp.Discrete([32,64,128]))\n",
        "HP_DROPOUT = hp.HParam('dropout', hp.RealInterval(0.2, 0.5))\n",
        "HP_OPTIMIZER = hp.HParam('optimizer', hp.Discrete(['adam', 'rmsprop', 'adadelta']))\n",
        "\n",
        "METRIC_ACCURACY = 'accuracy'\n",
        "\n",
        "with tf.summary.create_file_writer('logs/hparam_tuning').as_default():\n",
        "  hp.hparams_config(\n",
        "    hparams=[HP_NUM_UNITS, HP_DROPOUT, HP_OPTIMIZER],\n",
        "    metrics=[hp.Metric(METRIC_ACCURACY, display_name='Accuracy')],\n",
        "  )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iVxNVlS11Gvh"
      },
      "source": [
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.layers import InputLayer, Activation, Dense, Conv2D, MaxPool2D, Dropout, Flatten, BatchNormalization\n",
        "from tensorflow.keras.models import Sequential\n",
        "\n",
        "def train_test_model(hparams):\n",
        "  model_hparams = Sequential()\n",
        "\n",
        "  model_hparams.add(InputLayer(input_shape=[250,250,3]))\n",
        "\n",
        "  model_hparams.add(Conv2D(filters=4, kernel_size=3, strides=1, padding='same', activation='relu'))\n",
        "  model_hparams.add(Conv2D(filters=8, kernel_size=3, strides=1, padding='same', activation='relu'))\n",
        "  model_hparams.add(BatchNormalization())\n",
        "  model_hparams.add(MaxPool2D(pool_size=2, padding='same'))\n",
        "\n",
        "  model_hparams.add(Conv2D(filters=16, kernel_size=3, strides=1, padding='same', activation='relu'))\n",
        "  model_hparams.add(BatchNormalization())\n",
        "  model_hparams.add(MaxPool2D(pool_size=2, padding='same'))\n",
        "\n",
        "  model_hparams.add(Conv2D(filters=32, kernel_size=3, strides=1, padding='same', activation='relu'))\n",
        "  model_hparams.add(BatchNormalization())\n",
        "  model_hparams.add(MaxPool2D(pool_size=2, padding='same'))\n",
        "\n",
        "  model_hparams.add(Conv2D(filters=64, kernel_size=3, strides=1, padding='same', activation='relu'))\n",
        "  model_hparams.add(BatchNormalization())\n",
        "  model_hparams.add(MaxPool2D(pool_size=2, padding='same'))\n",
        "\n",
        "  model_hparams.add(Conv2D(filters=128, kernel_size=3, strides=1, padding='same', activation='relu'))\n",
        "  model_hparams.add(BatchNormalization())\n",
        "  model_hparams.add(MaxPool2D(pool_size=2, padding='same'))\n",
        "\n",
        "  model_hparams.add(Conv2D(filters=8, kernel_size=3, strides=1, padding='same', activation='relu'))\n",
        "  model_hparams.add(BatchNormalization())\n",
        "  model_hparams.add(MaxPool2D(pool_size=2, padding='same'))\n",
        "  model_hparams.add(Dropout(hparams[HP_DROPOUT]))\n",
        "\n",
        "  model_hparams.add(Flatten())\n",
        "\n",
        "  # Fully Connected Layer\n",
        "  model_hparams.add(Dense(hparams[HP_NUM_UNITS], activation='relu'))\n",
        "  model_hparams.add(Dropout(hparams[HP_DROPOUT]))\n",
        "  model_hparams.add(Dense(1, activation='softmax'))\n",
        "  \n",
        "  model_hparams.compile(\n",
        "      optimizer=hparams[HP_OPTIMIZER],\n",
        "      loss='categorical_crossentropy',\n",
        "      metrics=['accuracy'],\n",
        "  )\n",
        "\n",
        "  # model.fit(x_train, y_train, epochs=10) \n",
        "  model_hparams.fit(train_generator, epochs=50, validation_data=val_generator, verbose=1)\n",
        "  _, accuracy = model_hparams.evaluate(x_val, y_val)\n",
        "  return accuracy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wgRyZrdA1GyN"
      },
      "source": [
        "def run(run_dir, hparams):\n",
        "  with tf.summary.create_file_writer(run_dir).as_default():\n",
        "    hp.hparams(hparams)  # record the values used in this trial\n",
        "    accuracy = train_test_model(hparams)\n",
        "    tf.summary.scalar(METRIC_ACCURACY, accuracy, step=50)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m89prbLl1G0U"
      },
      "source": [
        "['adam', 'sgd', 'adadelta', 'rmsprop', 'adamx', 'nadam']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ykW_yivO1G3J"
      },
      "source": [
        "session_num = 0\n",
        "\n",
        "for num_units in HP_NUM_UNITS.domain.values:\n",
        "  for dropout_rate in (HP_DROPOUT.domain.min_value, HP_DROPOUT.domain.max_value):\n",
        "    for optimizer in HP_OPTIMIZER.domain.values:\n",
        "      hparams = {\n",
        "          HP_NUM_UNITS: num_units,\n",
        "          HP_DROPOUT: dropout_rate,\n",
        "          HP_OPTIMIZER: optimizer,\n",
        "      }\n",
        "      run_name = \"run-%d\" % session_num\n",
        "      print('--- Starting trial: %s' % run_name)\n",
        "      print({h.name: hparams[h] for h in hparams})\n",
        "      run('logs/hparam_tuning/' + run_name, hparams)\n",
        "      session_num += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZAsUBVww1SzR"
      },
      "source": [
        "%%bash\n",
        "wget -q 'https://storage.googleapis.com/download.tensorflow.org/tensorboard/hparams_demo_logs.zip'\n",
        "unzip -q hparams_demo_logs.zip -d logs/hparam_demo"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZDdgU1Vg1S2g"
      },
      "source": [
        "%tensorboard --logdir logs/hparam_tuning"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AuXpDhWM1S47"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JfSgO6cV1S7j"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}